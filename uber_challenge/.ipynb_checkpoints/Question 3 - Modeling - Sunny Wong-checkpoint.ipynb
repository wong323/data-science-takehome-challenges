{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3 Modeling\n",
    "\n",
    "Uber’s Driver team is interested in predicting which driver signups are most likely to start driving.\n",
    "To help explore this question, we have provided a sample dataset of a cohort of driver signups.\n",
    "\n",
    "The data was pulled a some time after they signed up to include the result of whether they\n",
    "actually completed their first trip. It also includes several pieces of background information\n",
    "gathered about the driver and their car.\n",
    "\n",
    "We would like you to use this data set to help understand what factors are best at predicting\n",
    "whether a signup will start to drive within 30 days of signing up, and offer suggestions to\n",
    "operationalize those insights to help Uber.\n",
    "\n",
    "See below for a description of the dataset. Please include any code you wrote for the analysis\n",
    "and delete the dataset when you have finished with the challenge. Please also call out any data\n",
    "related assumptions or issues that you encounter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A\n",
    "\n",
    "Perform any cleaning, exploratory analysis, and/or visualizations to use the provided data for this\n",
    "analysis (a few sentences/plots describing your approach will suffice). What fraction of the driver\n",
    "signups took a first trip within 30 days of signing up?\n",
    "\n",
    "### Data issues and exploration\n",
    "- how can records have value for first_complete_trip_timestamp but NaN for signup_timestamp (remove those records)\n",
    "- after removing records with Nan signup_timestamp, proportion of records that complete first ride within 30 days is 54%\n",
    "\n",
    "### Data assumptions\n",
    "- Nan values in any timestamp columns would mean event never happened, eg: a Nan first_complete_timestamp would mean user never gave a first ride\n",
    "- signup_timestamp must occur before bgc, vehicle added, and first complete ride\n",
    "\n",
    "\n",
    "### Data transformation\n",
    "- first_complete_trip_timestamp \n",
    "\n",
    "        -> convert to binary (1,0) where 1 is within 30 days since sign up and all else 0\n",
    "        \n",
    "\n",
    "- bgc_date\n",
    "\n",
    "        -> convert to binary (1,0) where 1 is driver did a bgc\n",
    "        -> days it took to complete bgc since signup\n",
    "           \n",
    "- vehicle_date \n",
    "\n",
    "        -> convert to binary(1,0) where 1 is driver register vehicle information\n",
    "        -> days it took to register vehicle since signup\n",
    "        \n",
    "- vehicle_year\n",
    "        -> identify whether vehicle registered is a recent model\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic import files, right now is just simply calling from my local, must change path if other wants to run it\n",
    "filepath = r'C:\\Users\\sunny.wong2\\JupyterNotebook\\Uber Assignment\\uber_assignment\\product_ds_exercise_2018_h2_dataset.csv'\n",
    "df = pd.read_csv(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis only focus on records with non null signup timestamp\n",
    "df['signup_label'] = df['signup_timestamp'].notnull()\n",
    "df = df[df['signup_label'] == True]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data_transformer class to any data transformation custom functions\n",
    "class data_transformer(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.sign_up_window = 30\n",
    "            \n",
    "    # create label of whether a first completed trip happened within 30 days\n",
    "    # assumption is that a Nan timestamp means there is no first trip completed\n",
    "    def create_final_label(self, days):\n",
    "        if days < self.sign_up_window:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    # calculate date difference (used to find how long it took for bgc and veh regis since signup date)\n",
    "    def extract_days_difference(self, input_delta):\n",
    "\n",
    "        # Attempt to coerce into Pandas time delta\n",
    "        delta = pd.Timedelta(input_delta)\n",
    "\n",
    "        # Attempt to extract number of days\n",
    "        days = np.NaN\n",
    "        if pd.notnull(delta):\n",
    "            days = delta.days\n",
    "\n",
    "        # Return result\n",
    "        return days\n",
    "    \n",
    "    # want a feature that looks at whether vehicle registered is \"new\" or not\n",
    "    def vehicle_year_bin(self, y):\n",
    "        if y > 2011:\n",
    "            return \"new\"\n",
    "        else:\n",
    "            return \"old\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create simple features based on whether the data exist\n",
    "df['bgc_known'] = df['bgc_date'].notnull()\n",
    "df['vehicle_inspection_known'] = df['vehicle_added_date'].notnull()\n",
    "df['signup_os_known'] = df['signup_os'].notnull()\n",
    "df['vehicle_make_known'] = df['vehicle_make'].notnull()\n",
    "df['drove_label'] = df['first_completed_trip_timestamp'].notnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert date columns into dates\n",
    "df['first_completed_trip_timestamp'] = pd.to_datetime(df['first_completed_trip_timestamp'], infer_datetime_format=True)\n",
    "df['vehicle_added_date'] = pd.to_datetime(df['vehicle_added_date'], infer_datetime_format=True)\n",
    "df['bgc_date'] = pd.to_datetime(df['bgc_date'], infer_datetime_format=True)\n",
    "df['signup_timestamp'] = pd.to_datetime(df['signup_timestamp'], infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute days difference, maybe important features since drivers who complete these actions are more commited\n",
    "dt = data_transformer()\n",
    "df['signup_to_bgc'] = (df['bgc_date'] - df['signup_timestamp']).apply(dt.extract_days_difference)\n",
    "df['signup_to_veh'] = (df['vehicle_added_date'] - df['signup_timestamp']).apply(dt.extract_days_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sunny.wong2\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# based on vehicle year, see if vehicle is a recent model\n",
    "df['vehicle_new_indicator'] = df['vehicle_year'].apply(dt.vehicle_year_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build label, if days took from signup to first trip is under 30days then 1 else 0\n",
    "df['signup_to_first_complete'] = (df['first_completed_trip_timestamp'] - df['signup_timestamp']).apply(dt.extract_days_difference)\n",
    "df['complete_trip_label'] = df['signup_to_first_complete'].apply(dt.create_final_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only columns considered for modelling\n",
    "columns = ['city_name',\n",
    "           'signup_os',\n",
    "           'signup_channel',\n",
    "           'vehicle_make',\n",
    "           'vehicle_model',\n",
    "           'vehicle_year',\n",
    "           'bgc_known',\n",
    "           'vehicle_inspection_known',\n",
    "           'signup_os_known',\n",
    "           'vehicle_make_known',\n",
    "           'signup_to_bgc',\n",
    "           'signup_to_veh',\n",
    "           'vehicle_new_indicator',\n",
    "           'complete_trip_label'\n",
    "          ]\n",
    "df = df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.546810791495444\n"
     ]
    }
   ],
   "source": [
    "# data explortory, \n",
    "# rate of drivers that have a complete trip after 30 days of signup is 54% - note this is after removing records with null signup date\n",
    "r = len(df.loc[(df['complete_trip_label'] == 1)]) / len(df)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B \n",
    "\n",
    "Build a predictive model to help Uber determine whether or not a driver signup will start driving\n",
    "within 30 days of signing up. Discuss why you chose your approach, what alternatives you\n",
    "considered, and any concerns you have. How valid is your model? Include any key indicators of\n",
    "model performance.\n",
    "\n",
    "- After the data transformation step, we now have a dataframe ready to build our predictive model\n",
    "- will create a simple model as baseline (decision tree)\n",
    "- build more advance models (such as random forest and gradient boosting) to beat the baseline model\n",
    "- use grid search and cross validation to find optimal hyperparameters\n",
    "- evaluate against test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection  import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import f1_score, confusion_matrix, precision_score, recall_score, accuracy_score\n",
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X is our predictors, y is the label we want to predict\n",
    "y = df['complete_trip_label']\n",
    "X = df.drop(['complete_trip_label'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11194\n",
      "11194\n"
     ]
    }
   ],
   "source": [
    "# sanity check to see if y and X have same number of rows\n",
    "print(len(y))\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# use function below to prepare our X dataframe for scikit learn models\n",
    "X_prepped = prep_df(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_df(input_df):\n",
    "    \n",
    "    prepped_df = input_df.copy()\n",
    "\n",
    "    # replace null values with not_known in these categorical variables\n",
    "    columns = ['signup_os', 'signup_channel', 'vehicle_make', 'vehicle_model', 'city_name', 'vehicle_year']\n",
    "    for c in columns:\n",
    "        prepped_df[c] = prepped_df[c].fillna('not_known')\n",
    "    \n",
    "    # a simple way to deal with NaN in these days difference features is to replace with the mean\n",
    "    columns = ['signup_to_bgc', 'signup_to_veh']\n",
    "    for c in columns:\n",
    "        prepped_df[c] = prepped_df[c].replace(np.NaN, df[c].mean())\n",
    "        \n",
    "    prepped_df = pd.get_dummies(prepped_df)\n",
    "    return prepped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function first splits into train and test, then do cross validation grid search on the train set \n",
    "# to identify best hyperparamters, using the best_fit model to validate against test set\n",
    "def train_model_with_cv(model, params, X, y):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "    # Use Train data to parameter selection in a Grid Search\n",
    "    gs_clf = GridSearchCV(model, params, n_jobs=1, cv=5)\n",
    "    gs_clf = gs_clf.fit(X_train, y_train)\n",
    "    model = gs_clf.best_estimator_\n",
    "\n",
    "    # Use best model and test data for final evaluation\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    _f1 = f1_score(y_test, y_pred, average='micro')\n",
    "    _confusion = confusion_matrix(y_test, y_pred).ravel()\n",
    "    _accuracy = accuracy_score(y_test, y_pred)\n",
    "    _precision = precision_score(y_test, y_pred)\n",
    "    _recall = recall_score(y_test, y_pred)\n",
    "    _statistics = {'f1_score': _f1,\n",
    "                   'confusion_matrix': 'tn, fp, fn, tp' + str(_confusion),\n",
    "                   'accuracy': _accuracy,\n",
    "                   'precision': _precision,\n",
    "                   'recall': _recall\n",
    "                   }\n",
    "\n",
    "    return model, _statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1_score': 0.5737483085250338, 'confusion_matrix': 'tn, fp, fn, tp[ 676 1005  570 1444]', 'accuracy': 0.5737483085250338, 'precision': 0.5896284197631686, 'recall': 0.7169811320754716}\n"
     ]
    }
   ],
   "source": [
    "# baseline model using decision tree model\n",
    "clf = DecisionTreeClassifier()\n",
    "param_grid = {\"max_depth\": [10, 15, 20],\n",
    "              \"min_impurity_decrease\": [0],\n",
    "              \"criterion\": [\"gini\"],\n",
    "              \"min_samples_split\": [50],\n",
    "              \"min_samples_leaf\": [50],\n",
    "              \"max_features\": [None]\n",
    "              }\n",
    "\n",
    "dt_model , stats = train_model_with_cv(clf, param_grid, X_prepped, y)\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1_score': 0.56617050067659, 'confusion_matrix': 'tn, fp, fn, tp[ 335 1346  257 1757]', 'accuracy': 0.56617050067659, 'precision': 0.5662262326780535, 'recall': 0.8723932472691162}\n"
     ]
    }
   ],
   "source": [
    "# random forest model\n",
    "clf = RandomForestClassifier()\n",
    "param_grid = {\"n_estimators\": [100, 150],\n",
    "                  \"max_depth\": [3, 8, 12],\n",
    "                  \"max_features\": [\"auto\", \"sqrt\"],\n",
    "                  \"min_samples_split\": [30, 75],\n",
    "                  \"min_samples_leaf\": [30, 75],\n",
    "                  \"bootstrap\": [True],\n",
    "                  \"criterion\": [\"gini\"]\n",
    "              }\n",
    "\n",
    "rf_model , stats = train_model_with_cv(clf, param_grid, X_prepped, y)\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1_score': 0.5732070365358592, 'confusion_matrix': 'tn, fp, fn, tp[ 595 1086  491 1523]', 'accuracy': 0.5732070365358592, 'precision': 0.5837485626676888, 'recall': 0.7562065541211519}\n"
     ]
    }
   ],
   "source": [
    "# gradient boosting model\n",
    "clf = XGBClassifier()\n",
    "param_grid = {\"learning_rate\": [0.1],\n",
    "              \"n_estimators\": [100, 150],  # Number of estimators\n",
    "              \"max_depth\": [3, 8, 15],  # maximum depth of decision trees\n",
    "              \"colsample_bytree\": [0.33, 0.66],   # Criterion for splitting\n",
    "              \"subsample\": [0.5, 0.8, 1]\n",
    "             }\n",
    "\n",
    "\n",
    "gb_model , stats = train_model_with_cv(clf, param_grid, X_prepped, y)\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the models I tested performed about the same. This is due to the quality of the data. If I was able to collect more features, we’ll see the algorithms differ a little more in performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part C\n",
    "\n",
    "Briefly discuss how Uber might leverage the insights gained from the model to generate more\n",
    "first trips (again, a few ideas/sentences will suffice)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using trained random forest model, can take advantage of its feature importances to see which features are strong predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_important_list = sorted(zip(map(lambda x: round(x, 4), rf_model.feature_importances_), list(X_prepped)), reverse=True)\n",
    "feature_important_list_top5 = feature_important_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.1708, 'signup_channel_Referral'), (0.1017, 'signup_to_bgc'), (0.0904, 'signup_channel_R2D'), (0.0695, 'signup_to_veh'), (0.0628, 'signup_os_known')]\n"
     ]
    }
   ],
   "source": [
    "# show top 5 features from feature important list\n",
    "print(feature_important_list_top5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insights to Leverage\n",
    "The main factor that is best at predicting whether someone who signs up completes their first drive is that signups are completed thru referral. Therefore Uber should increase their incentive to users for successful referrals.\n",
    "\n",
    "Another factor important to predicting whether someone who signs up completes their first drive is the time it takes them to submit their background check consent form. Uber may want to come up with ways to encourage their signups to complete their background check consent form as soon as possible such as offers or incentives."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
